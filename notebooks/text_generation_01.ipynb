{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Text Generation \n",
    "> A Practioners Guide : Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Language\n",
    "\n",
    "Language is one of the most complex aspects of our existence. We use language to communicate our thoughts and choices. Every language is defined with a list of characters called the alphabet, a vocabulary and a set of rules called grammar. Yet it is not a trivial task to understand and learn a language. \n",
    "\n",
    "It takes years for a human to grasp a few languages, let alone become a master of it. Most languages have vast vocabularies which are ever expanding along with complex and fuzzy grammatical rules and structures. We see/think and write/share differently. To put simply, languages are ambiguous. The ambiguity, sarcasm, context, and continuous changes to usage patterns are some of the challenges associated with language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples of ambiguity**\n",
    "\n",
    "+ **The bowler made the batsman duck.**\n",
    "> The word duck, is it verb or noun?\n",
    "\n",
    "+ **Stolen painting found by tree.**\n",
    "> The word tree, is it an actor or a place?\n",
    "\n",
    "+ **Are you comfortable with python?**\n",
    "> The word python, is it representing the programming language python or a snake or something else? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turing Test**\n",
    "\n",
    "Alan Turing designed the Turing test in 1950. It associated with testing a systemâ€™s ability to *exhibit intelligent behavior without being distinguishable from a human*. Though it is the ultimate test for Artificial Intelligence, understanding language is one of the key milestones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks or RNNs are a class of networks that allow _previous outputs_ to be used as inputs along with memory/hidden units. This ability to use previous inputs enables RNNs to handle variable length sequential inputs with ease.\n",
    "\n",
    "**A typical RNN looks like this:**\n",
    "<img src=\"illustrations/rnn.png\">\n",
    "At time _t_<sub>1</sub>, input x<sub>1</sub> generates output y<sub>1</sub>. At time _t_<sub>2</sub>, x<sub>2</sub> along with y<sub>1</sub> (the previous output) to generate output y<sub>2</sub> and so on. Unlike usual feed forward networks where every input is independent of others, RNN attaches a notion of previous outputs impacting the current and upcoming ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As showcased in the previous section, RNNs have a notion of utilizing previous inputs and thus handle variable length sequential inputs. This is in contrast with normal feed forward networks, CNNs and other types which handle only fixed sized inputs.\n",
    "\n",
    "This ability of RNNs provides some advantages apart, such as:\n",
    " - Weights are shared across time dimension\n",
    " - Model size does not increase with input size\n",
    " - Ability to handle variable sized inputs\n",
    " \n",
    " \n",
    " These advantages enable RNNs to used for different sequence related tasks, such as analysing time series information , audio data, as well as textual data. \n",
    " \n",
    "Since our focus is on text generation, we will utilize the ability of RNNs in a **sequence to sequence** setting, i.e. the model takes text as input and generates text as output. This is also termed as **many to many** setting.\n",
    "\n",
    "<img src=\"illustrations/seq2seq.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By far the most widely used application from the NLP world is **language modeling**. We use it daily on our phone keyboards, email applications and a ton of other places. \n",
    "<img src=\"illustrations/lm.png\">\n",
    "[Image Source](https://www.androidpolice.com/wp-content/uploads/2017/05/nexus2cee_assistant-suggestions.png)\n",
    "\n",
    "\n",
    "In simple words, a language model takes certain text as input context to generate the next set of words as output. This is interesting because a language model tries to understand the input context, the language structure (though in a very naive way) to predict the next word(s). We use it in the form of text completion utilities on search engines, chat platforms, emails etc. all the time. Language models are a perfect real life application of NLP and showcase the power of RNNs.\n",
    "\n",
    "Language models can be developed train in different ways. The most common and widely used method is the sliding window approach. The model takes a small window of text as input and tried to predict the next word as the output. The following figure illustrates the same visually.\n",
    "\n",
    "<img src=\"illustrations/lm_training.png\">\n",
    "\n",
    "\n",
    "We typically train language models on huge corpus of text to help them understand which words are used in what context. This is quite intiutive and similar to how a child typically learns language. Amazing, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [CS230 - Deep Learning CheatSheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)\n",
    " - [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    " - [Word2Vec Illustrated](http://jalammar.github.io/illustrated-word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
